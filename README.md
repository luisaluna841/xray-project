# Classifica√ß√£o de Pneumonia em Raio-X Tor√°cico

> Desafio Individual ‚Äî Liga Acad√™mica de Intelig√™ncia Artificial (Ligia)  
> Universidade Federal de Pernambuco ‚Äî Processo Seletivo 2026  
> Trilha: Vis√£o Computacional  
> Autor: [luisaluna841](https://github.com/luisaluna841)

---

## üìÑ Relat√≥rio T√©cnico

O relat√≥rio completo est√° dispon√≠vel em [`relatorio.pdf`](./relatorio.pdf), incluindo an√°lise explorat√≥ria, metodologia, resultados, interpretabilidade Grad-CAM e conclus√µes.

---

## Vis√£o Geral

Este projeto desenvolve um classificador bin√°rio de imagens de raio-X tor√°cico para detec√ß√£o de pneumonia, utilizando Transfer Learning com arquiteturas pr√©-treinadas no ImageNet. Quatro experimentos foram conduzidos de forma sistem√°tica e controlada, com an√°lise cr√≠tica baseada em m√©tricas cl√≠nicas.

**Modelo com melhor desempenho no Kaggle:** ResNet18 Baseline (`submission_resnet18.csv`) ‚Äî ROC-AUC: 0.99543  
**Modelo recomendado clinicamente:** ResNet18 com Class Weighting (H3) ‚Äî Recall: 0.9943 | FNs: 5  
**M√©trica principal:** ROC-AUC  
**Dataset:** [Kaggle ‚Äì L√≠gia - CV](https://www.kaggle.com/competitions/ligia-compviz/overview)

---

## Estrutura do Reposit√≥rio

```
xray-project/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_metadata.csv      # Metadados completos do treino
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_split.csv         # Split de treino (congelado, seed=42)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val_split.csv           # Split de valida√ß√£o (congelado, seed=42)
‚îÇ   ‚îú‚îÄ‚îÄ train/                      # ‚Üê voc√™ preenche (n√£o sobe no git)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/
‚îÇ   ‚îú‚îÄ‚îÄ test_images/                # ‚Üê voc√™ preenche (n√£o sobe no git)
‚îÇ   ‚îî‚îÄ‚îÄ test.csv
‚îÇ
‚îú‚îÄ‚îÄ models/                         # Pesos treinados .pt ‚Äî n√£o sobem no git
‚îÇ   ‚îú‚îÄ‚îÄ resnet18_light_noCW.pt      # Baseline
‚îÇ   ‚îú‚îÄ‚îÄ densenet121_light_noCW.pt   # H1
‚îÇ   ‚îú‚îÄ‚îÄ resnet18_strong_noCW.pt     # H2
‚îÇ   ‚îî‚îÄ‚îÄ resnet18_light_CW.pt        # H3 ‚òÖ recomendado clinicamente
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_build_metadata_and_split.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_preprocessing_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_baseline_resnet18.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_h1_densenet121.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 06_h2_strong_augmentation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 07_h3_classweight.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 08_model_comparison.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 09_gradcam.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 10_generate_submission.ipynb
‚îÇ
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                    # Gr√°ficos e visualiza√ß√µes (sobem no git)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gradcam/                # Mapas de calor Grad-CAM
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                    # Hist√≥rico de treinamento .pkl (sobem no git)
‚îÇ   ‚îî‚îÄ‚îÄ submissions/
‚îÇ       ‚îú‚îÄ‚îÄ submission_resnet18.csv                  # ‚Üê melhor no Kaggle
‚îÇ       ‚îú‚îÄ‚îÄ submission_densenet121_light_noCW.csv
‚îÇ       ‚îú‚îÄ‚îÄ submission_resnet18_light_CW.csv
‚îÇ       ‚îî‚îÄ‚îÄ submission_resnet18_strong_noCW.csv
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                  # Dataset customizado (XRayDataset)
‚îÇ   ‚îú‚îÄ‚îÄ model.py                    # Defini√ß√£o dos modelos
‚îÇ   ‚îú‚îÄ‚îÄ train_utils.py              # Loop de treinamento e m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ transforms.py               # Transforma√ß√µes de imagem
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                    # Seed global e utilit√°rios
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ relatorio.pdf
‚îú‚îÄ‚îÄ CONCLUSAO.md
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

## Instala√ß√£o

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/luisaluna841/xray-project.git
cd xray-project
```

### 2. Criar e ativar ambiente virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux / macOS
python -m venv venv
source venv/bin/activate
```

### 3. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

---

## Download dos Dados

As imagens **n√£o est√£o inclu√≠das no reposit√≥rio**. Para obt√™-las:

**1.** Acesse a competi√ß√£o: [Kaggle ‚Äì L√≠gia - CV](https://www.kaggle.com/competitions/ligia-compviz/overview)  
**2.** Fa√ßa login, aceite os termos (bot√£o **Join Competition**) e v√° at√© a aba **Data**  
**3.** Clique em **Download All** e salve o `.zip` no seu computador  
**4.** Extraia o arquivo e mova as pastas manualmente para dentro de `data/`, respeitando **exatamente** esta estrutura:

```
data/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/        ‚Üê cole aqui as imagens da pasta NORMAL
‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/     ‚Üê cole aqui as imagens da pasta PNEUMONIA
‚îú‚îÄ‚îÄ test_images/       ‚Üê cole aqui as imagens de teste
‚îî‚îÄ‚îÄ test.csv           ‚Üê cole aqui o arquivo de metadados
```

> ‚ö†Ô∏è **N√£o mexa em `data/metadata/`** ‚Äî essa pasta j√° est√° no reposit√≥rio com os splits congelados que garantem a reprodutibilidade de todos os experimentos.

---

## Reprodu√ß√£o dos Experimentos

Execute os notebooks **na ordem num√©rica**:

| # | Notebook | Descri√ß√£o |
|---|---|---|
| 01 | `01_build_metadata_and_split.ipynb` | Constr√≥i metadados e congela os splits |
| 02 | `02_eda.ipynb` | An√°lise explorat√≥ria e justificativas metodol√≥gicas |
| 03 | `03_preprocessing_analysis.ipynb` | An√°lise de pr√©-processamento e augmentation |
| 04 | `04_baseline_resnet18.ipynb` | Treinamento do Baseline |
| 05 | `05_h1_densenet121.ipynb` | Hip√≥tese 1: DenseNet121 |
| 06 | `06_h2_strong_augmentation.ipynb` | Hip√≥tese 2: Augmentation Forte |
| 07 | `07_h3_classweight.ipynb` | Hip√≥tese 3: Class Weighting |
| 08 | `08_model_comparison.ipynb` | Compara√ß√£o final entre experimentos |
| 09 | `09_gradcam.ipynb` | Interpretabilidade Grad-CAM |
| 10 | `10_generate_submission.ipynb` | Gera√ß√£o do arquivo de submiss√£o |

> ‚ö†Ô∏è **N√£o re-execute o notebook 01.** Os splits est√£o congelados em `data/metadata/` e s√£o compartilhados por todos os experimentos ‚Äî re-executar alteraria a divis√£o e tornaria as compara√ß√µes inv√°lidas.

---

## Reprodutibilidade

Este projeto foi projetado para rodar do mesmo jeito em qualquer m√°quina:

- **Seed 42** fixada globalmente em todos os experimentos via `src/utils.py`
- **Splits congelados** em `data/metadata/` ‚Äî mesma divis√£o treino/valida√ß√£o para todos os modelos
- **Caminhos relativos** em todos os notebooks ‚Äî nenhum caminho absoluto
- **Vers√µes fixas** de depend√™ncias em `requirements.txt`
- **Crit√©rio de salvamento determin√≠stico** ‚Äî melhor √©poca por ROC-AUC de valida√ß√£o
- **Hist√≥rico completo** de m√©tricas salvo em `outputs/metrics/*.pkl`

---

## Hip√≥teses Experimentais

Todos os experimentos compartilham os mesmos splits, hiperpar√¢metros base (lr=1e-4, batch=32, epochs=10, Adam + ReduceLROnPlateau) e pesos pr√©-treinados no ImageNet. Cada hip√≥tese altera **uma √∫nica vari√°vel** em rela√ß√£o ao Baseline.

### Baseline ‚Äî ResNet18 + Augmentation Leve + Sem Class Weight

Modelo de refer√™ncia com ResNet18, *flip* horizontal e rota√ß√£o ¬±5¬∞. **Obteve o melhor ROC-AUC na competi√ß√£o: 0.99543**.

### Hip√≥tese 1 (H1) ‚Äî Arquitetura: DenseNet121

**Pergunta:** Conex√µes densas entre camadas capturam padr√µes mais sutis de pneumonia do que a adi√ß√£o residual da ResNet18?

**Resultado: n√£o confirmada.** 19 FNs vs 16 do Baseline. A maior complexidade foi desfavor√°vel para o tamanho moderado do dataset ‚Äî a ResNet18 converge com maior estabilidade.

> A DenseNet121 n√£o √© apenas "mais profunda" ‚Äî representa um paradigma distinto: reutiliza√ß√£o de *features* por concatena√ß√£o vs adi√ß√£o residual. A compara√ß√£o √© entre mecanismos de propaga√ß√£o de informa√ß√£o, n√£o apenas profundidade.

### Hip√≥tese 2 (H2) ‚Äî Data Augmentation Intenso

**Pergunta:** Augmentation mais agressivo (rota√ß√£o ¬±15¬∞, affine, jitter de brilho/contraste) atua como regulariza√ß√£o eficaz?

**Resultado: n√£o confirmada.** Pior resultado cl√≠nico: 24 FNs e Recall de 0.9725. Transforma√ß√µes geom√©tricas agressivas distorcem consolida√ß√µes e infiltrados ‚Äî padr√µes patol√≥gicos sens√≠veis a deforma√ß√µes.

### Hip√≥tese 3 (H3) ‚Äî Pondera√ß√£o de Classes ‚úì

**Pergunta:** Class weighting na fun√ß√£o de perda melhora a Sensitivity para Pneumonia, reduzindo Falsos Negativos?

**Resultado: confirmada.** √â o modelo recomendado clinicamente ‚Äî ver se√ß√£o de Resultados.

---

## Resultados

### Desempenho no Kaggle

| Submiss√£o | ROC-AUC (p√∫blico) |
|---|---|
| **submission_resnet18.csv** (Baseline) ‚úì selecionada | **0.99543** ‚Üê melhor resultado |
| submission_densenet121_light_noCW.csv (H1) | 0.99359 |
| submission_resnet18_strong_noCW.csv (H2) | 0.99152 |
| submission_resnet18_light_CW.csv (H3) | 0.99074 |

### Desempenho na Valida√ß√£o Interna (threshold = 0.5)

| Modelo | AUC | F1 | Recall | Precision | FNs |
|---|---|---|---|---|---|
| Baseline (ResNet18) | 0.9990 | 0.9885 | 0.9817 | 0.9953 | 16 |
| H1 ‚Äî DenseNet121 | 0.9989 | 0.9873 | 0.9782 | 0.9965 | 19 |
| H2 ‚Äî Strong Aug | 0.9990 | 0.9849 | 0.9725 | 0.9976 | 24 |
| **H3 ‚Äî Class Weight ‚òÖ** | **0.9992** | **0.9931** | **0.9943** | 0.9920 | **5** |

### Por que o H3 √© o modelo recomendado clinicamente?

Em termos de ROC-AUC ‚Äî tanto no Kaggle quanto na valida√ß√£o interna ‚Äî todos os modelos apresentam desempenho equivalente e alto. Isso indica que qualquer experimento seria uma solu√ß√£o tecnicamente v√°lida do ponto de vista de capacidade discriminativa global.

No entanto, **ROC-AUC agrega o desempenho ao longo de todos os limiares de decis√£o poss√≠veis**, n√£o refletindo o comportamento cl√≠nico em um limiar fixo de opera√ß√£o. A an√°lise em threshold 0.5 ‚Äî mais representativa do uso cl√≠nico real ‚Äî revela diferen√ßas substanciais:

O H3 reduz os **Falsos Negativos de 16 para 5 ‚Äî redu√ß√£o de 69%**. Em contexto diagn√≥stico, um Falso Negativo representa um paciente com pneumonia dispensado sem tratamento. O custo assim√©trico entre FN e FP justifica a escolha de um modelo com maior Sensitivity (0.9943 vs 0.9817), mesmo que isso implique leve redu√ß√£o de Specificity (0.9738 vs 0.9850) e AUC inferior no leaderboard p√∫blico.

O H3 √© o √∫nico experimento **explicitamente desenhado para esse tradeoff cl√≠nico**, e a an√°lise Grad-CAM confirma ativa√ß√µes concentradas em regi√µes anatomicamente plaus√≠veis.

---

## Interpretabilidade (Grad-CAM)

A an√°lise Grad-CAM foi aplicada nos modelos Baseline e H3 para verificar se as decis√µes se baseiam em regi√µes anatomicamente plaus√≠veis. Os mapas de calor est√£o em `outputs/figures/gradcam/`.

O **"p"** nas figuras √© a probabilidade de sa√≠da do softmax para a classe Pneumonia. Nos FNs do Baseline (p ‚âà 0.44), o modelo erra pr√≥ximo ao limiar sem sinalizar d√∫vida. Nos FNs do H3 (p < 0.20), o modelo erra com incerteza expl√≠cita ‚Äî em um sistema de triagem real, esses casos podem ser encaminhados para revis√£o humana, transformando o erro em alerta em vez de dispensa silenciosa.

---

## Depend√™ncias

```
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.23.0
pandas>=1.5.0
matplotlib>=3.6.0
seaborn>=0.12.0
scikit-learn>=1.2.0
Pillow>=9.3.0
tqdm>=4.64.0
opencv-python>=4.7.0
kaggle>=1.5.12
```

```bash
pip install -r requirements.txt
```



---

## Reprodutibilidade

Seed global fixada em **42** em todos os experimentos via `src/utils.py`:

```python
set_seed(42)
```

Os splits de treino e valida√ß√£o est√£o congelados nos arquivos CSV e s√£o compartilhados entre todos os experimentos, garantindo compara√ß√£o justa e controlada.

---

*Liga Acad√™mica de Intelig√™ncia Artificial ‚Äî UFPE, 2026*