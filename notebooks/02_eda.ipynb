{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 02 — Análise Exploratória de Dados (EDA)\n",
    "\n",
    "Projeto: Classificação de Pneumonia em Raio-X  \n",
    "Liga Acadêmica de Inteligência Artificial — UFPE\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Esta análise exploratória tem caráter **metodológico e decisório**:\n",
    "cada achado é diretamente vinculado a uma escolha experimental.\n",
    "\n",
    "| Achado do EDA | Decisão Metodológica |\n",
    "|---|---|\n",
    "| Desbalanceamento entre classes | → Hipótese 3: Class Weighting |\n",
    "| Tamanho moderado do dataset | → Transfer Learning (não treinar do zero) |\n",
    "| Alta variabilidade de dimensões | → Resize + CenterCrop padronizados |\n",
    "| Artefatos nas bordas | → CenterCrop (0.9 do resize) |\n",
    "| Padrões espaciais/texturais | → CNN como arquitetura base |\n",
    "| Diferenças visuais sutis em alguns casos | → Testar DenseNet121 (H1) |\n",
    "| Distribuição ampla de intensidades | → Normalização ImageNet |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "figures_dir = os.path.join(PROJECT_ROOT, \"outputs\", \"figures\")\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Figures dir: \", figures_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = os.path.join(PROJECT_ROOT, \"data\", \"metadata\")\n",
    "\n",
    "df       = pd.read_csv(os.path.join(metadata_dir, \"train_metadata.csv\"))\n",
    "train_df = pd.read_csv(os.path.join(metadata_dir, \"train_split.csv\"))\n",
    "val_df   = pd.read_csv(os.path.join(metadata_dir, \"val_split.csv\"))\n",
    "\n",
    "print(f\"Dataset completo: {len(df)} imagens\")\n",
    "print(f\"Split treino:     {len(train_df)} imagens\")\n",
    "print(f\"Split validação:  {len(val_df)} imagens\")\n",
    "print()\n",
    "print(df[\"label\"].value_counts().rename({0: \"Normal\", 1: \"Pneumonia\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 3. Distribuição de Classes — Motivação para o Class Weighting\n",
    "\n",
    "**Achado que fundamenta a Hipótese 3 (H3).**\n",
    "\n",
    "O desbalanceamento entre as classes impõe um viés natural ao modelo:\n",
    "sem qualquer intervenção, o modelo tende a favorecer a classe majoritária\n",
    "(Pneumonia), o que pode resultar em alto Recall mas baixa Specificity,\n",
    "ou vice-versa dependendo da distribuição.\n",
    "\n",
    "A ponderação de classes (class weighting) corrige esse viés atribuindo\n",
    "maior peso à classe minoritária na função de perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "COLORS_CLASS = {\"Normal\": \"#5B8DB8\", \"Pneumonia\": \"#C0504D\"}\n",
    "\n",
    "# --- Plot 1: Dataset completo ---\n",
    "counts_full = df[\"label\"].value_counts().rename({0: \"Normal\", 1: \"Pneumonia\"})\n",
    "bars = axes[0].bar(counts_full.index, counts_full.values,\n",
    "                   color=[COLORS_CLASS[k] for k in counts_full.index],\n",
    "                   edgecolor=\"white\", width=0.5)\n",
    "for bar, val in zip(bars, counts_full.values):\n",
    "    pct = val / counts_full.sum() * 100\n",
    "    axes[0].text(bar.get_x()+bar.get_width()/2, bar.get_height()+20,\n",
    "                 f\"{val}\\n({pct:.1f}%)\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Dataset Completo\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Número de imagens\", fontsize=10)\n",
    "axes[0].set_ylim(0, max(counts_full.values) * 1.2)\n",
    "axes[0].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# --- Plot 2: Split Treino ---\n",
    "counts_train = train_df[\"label\"].value_counts().rename({0: \"Normal\", 1: \"Pneumonia\"})\n",
    "bars2 = axes[1].bar(counts_train.index, counts_train.values,\n",
    "                    color=[COLORS_CLASS[k] for k in counts_train.index],\n",
    "                    edgecolor=\"white\", width=0.5)\n",
    "for bar, val in zip(bars2, counts_train.values):\n",
    "    pct = val / counts_train.sum() * 100\n",
    "    axes[1].text(bar.get_x()+bar.get_width()/2, bar.get_height()+10,\n",
    "                 f\"{val}\\n({pct:.1f}%)\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "axes[1].set_title(\"Split de Treino\", fontsize=11, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Número de imagens\", fontsize=10)\n",
    "axes[1].set_ylim(0, max(counts_train.values) * 1.2)\n",
    "axes[1].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# --- Plot 3: Ratio de desbalanceamento por split ---\n",
    "ratios = {\n",
    "    \"Completo\": counts_full.get(\"Pneumonia\", 0) / counts_full.get(\"Normal\", 1),\n",
    "    \"Treino\":   counts_train.get(\"Pneumonia\", 0) / counts_train.get(\"Normal\", 1),\n",
    "    \"Validação\": (val_df[\"label\"]==1).sum() / max((val_df[\"label\"]==0).sum(), 1),\n",
    "}\n",
    "axes[2].bar(ratios.keys(), ratios.values(), color=[\"#7DBE7D\",\"#5B8DB8\",\"#E8A838\"],\n",
    "            edgecolor=\"white\", width=0.4)\n",
    "axes[2].axhline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1.5,\n",
    "                label=\"Balanceamento perfeito (ratio=1)\")\n",
    "for i, (k, v) in enumerate(ratios.items()):\n",
    "    axes[2].text(i, v + 0.02, f\"{v:.2f}x\", ha=\"center\",\n",
    "                 fontsize=11, fontweight=\"bold\")\n",
    "axes[2].set_title(\"Ratio Pneumonia / Normal\", fontsize=11, fontweight=\"bold\")\n",
    "axes[2].set_ylabel(\"Ratio\", fontsize=10)\n",
    "axes[2].legend(fontsize=9)\n",
    "axes[2].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Distribuição de Classes — Motivação para Class Weighting (H3)\",\n",
    "             fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "# Caixa de decisão\n",
    "fig.text(0.5, -0.05,\n",
    "         \"→ Desbalanceamento moderado (~2.7x) presente nos splits. \"\n",
    "         \"Fundamenta o uso de class weighting (H3) na função de perda.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_distribuicao_classes.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 4. Dimensões das Imagens — Motivação para Resize e Transfer Learning\n",
    "\n",
    "**Achados que fundamentam:**\n",
    "- Resize padronizado para 224×224 (padrão ImageNet)\n",
    "- Transfer Learning: dataset de tamanho moderado não justifica treino do zero\n",
    "- CenterCrop de 90% para reduzir artefatos periféricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coletando dimensões das imagens (amostra de 300)...\")\n",
    "\n",
    "sample_df = df.sample(min(300, len(df)), random_state=42)\n",
    "widths, heights, aspects = [], [], []\n",
    "\n",
    "for path in sample_df[\"path\"]:\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        w, h = img.size\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "        aspects.append(w / h)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"Largura — min: {min(widths)}, max: {max(widths)}, média: {np.mean(widths):.0f}\")\n",
    "print(f\"Altura  — min: {min(heights)}, max: {max(heights)}, média: {np.mean(heights):.0f}\")\n",
    "print(f\"Total de imagens no dataset: {len(df)}\")\n",
    "print()\n",
    "\n",
    "# Categorias de tamanho\n",
    "n_pequenas  = sum(1 for w, h in zip(widths, heights) if w < 500 or h < 500)\n",
    "n_medias    = sum(1 for w, h in zip(widths, heights) if 500 <= w <= 1500 and 500 <= h <= 1500)\n",
    "n_grandes   = sum(1 for w, h in zip(widths, heights) if w > 1500 or h > 1500)\n",
    "\n",
    "print(f\"Imagens pequenas (<500px):  {n_pequenas}\")\n",
    "print(f\"Imagens médias (500-1500px): {n_medias}\")\n",
    "print(f\"Imagens grandes (>1500px):  {n_grandes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4.5))\n",
    "\n",
    "# Largura\n",
    "axes[0].hist(widths, bins=30, color=\"#5B8DB8\", edgecolor=\"white\")\n",
    "axes[0].axvline(np.mean(widths), color=\"red\", linestyle=\"--\",\n",
    "                linewidth=1.5, label=f\"Média: {np.mean(widths):.0f}px\")\n",
    "axes[0].axvline(224, color=\"orange\", linestyle=\":\",\n",
    "                linewidth=2, label=\"Resize alvo: 224px\")\n",
    "axes[0].set_title(\"Distribuição de Largura\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Pixels\", fontsize=9)\n",
    "axes[0].set_ylabel(\"Frequência\", fontsize=9)\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# Altura\n",
    "axes[1].hist(heights, bins=30, color=\"#C0504D\", edgecolor=\"white\")\n",
    "axes[1].axvline(np.mean(heights), color=\"red\", linestyle=\"--\",\n",
    "                linewidth=1.5, label=f\"Média: {np.mean(heights):.0f}px\")\n",
    "axes[1].axvline(224, color=\"orange\", linestyle=\":\",\n",
    "                linewidth=2, label=\"Resize alvo: 224px\")\n",
    "axes[1].set_title(\"Distribuição de Altura\", fontsize=11, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"Pixels\", fontsize=9)\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# Scatter Largura x Altura\n",
    "axes[2].scatter(widths, heights, alpha=0.3, s=15, color=\"#7DBE7D\")\n",
    "axes[2].plot([0, max(max(widths), max(heights))],\n",
    "             [0, max(max(widths), max(heights))],\n",
    "             \"k--\", linewidth=1, label=\"Proporção 1:1\")\n",
    "axes[2].set_title(\"Largura × Altura\", fontsize=11, fontweight=\"bold\")\n",
    "axes[2].set_xlabel(\"Largura (px)\", fontsize=9)\n",
    "axes[2].set_ylabel(\"Altura (px)\", fontsize=9)\n",
    "axes[2].legend(fontsize=8)\n",
    "axes[2].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Distribuição de Dimensões das Imagens — Motivação para Resize Padronizado\",\n",
    "             fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "fig.text(0.5, -0.06,\n",
    "         \"→ Alta variabilidade de dimensões exige resize padronizado (224×224). \"\n",
    "         \"Dataset de ~5k imagens favorece transfer learning sobre treino do zero.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_dimensoes.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 5. Distribuição de Intensidade de Pixels por Classe\n",
    "\n",
    "**Achados que fundamentam:**\n",
    "- Diferenças de textura e densidade entre Normal e Pneumonia\n",
    "- Normalização com média/std do ImageNet\n",
    "- CNNs como escolha arquitetural (capturam padrões espaciais/texturais)\n",
    "\n",
    "Imagens de pneumonia tendem a apresentar maior densidade\n",
    "em regiões pulmonares (consolidações, infiltrados),\n",
    "refletindo em distribuições de intensidade distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculando histogramas por classe (amostra de 150 por classe)...\")\n",
    "\n",
    "pixels_normal    = []\n",
    "pixels_pneumonia = []\n",
    "means_normal, means_pneumonia = [], []\n",
    "stds_normal,  stds_pneumonia  = [], []\n",
    "\n",
    "sample_normal    = df[df[\"label\"] == 0].sample(min(150, (df[\"label\"]==0).sum()), random_state=42)\n",
    "sample_pneumonia = df[df[\"label\"] == 1].sample(min(150, (df[\"label\"]==1).sum()), random_state=42)\n",
    "\n",
    "for path in sample_normal[\"path\"]:\n",
    "    try:\n",
    "        arr = np.array(Image.open(path).convert(\"L\").resize((224, 224))).flatten()\n",
    "        pixels_normal.extend(arr)\n",
    "        means_normal.append(arr.mean())\n",
    "        stds_normal.append(arr.std())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "for path in sample_pneumonia[\"path\"]:\n",
    "    try:\n",
    "        arr = np.array(Image.open(path).convert(\"L\").resize((224, 224))).flatten()\n",
    "        pixels_pneumonia.extend(arr)\n",
    "        means_pneumonia.append(arr.mean())\n",
    "        stds_pneumonia.append(arr.std())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"Normal    — média de intensidade: {np.mean(means_normal):.1f} ± {np.std(means_normal):.1f}\")\n",
    "print(f\"Pneumonia — média de intensidade: {np.mean(means_pneumonia):.1f} ± {np.std(means_pneumonia):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Histograma de pixels\n",
    "axes[0].hist(pixels_normal, bins=60, alpha=0.6, color=\"#5B8DB8\",\n",
    "             label=\"Normal\", density=True)\n",
    "axes[0].hist(pixels_pneumonia, bins=60, alpha=0.6, color=\"#C0504D\",\n",
    "             label=\"Pneumonia\", density=True)\n",
    "axes[0].set_title(\"Distribuição de Intensidade de Pixels\\npor Classe\",\n",
    "                  fontsize=11, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Intensidade (0-255)\", fontsize=9)\n",
    "axes[0].set_ylabel(\"Densidade\", fontsize=9)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# Boxplot da média por imagem\n",
    "data_means = [means_normal, means_pneumonia]\n",
    "bp = axes[1].boxplot(data_means, labels=[\"Normal\", \"Pneumonia\"],\n",
    "                     patch_artist=True, notch=True,\n",
    "                     medianprops=dict(color=\"black\", linewidth=2))\n",
    "for patch, color in zip(bp[\"boxes\"], [\"#5B8DB8\", \"#C0504D\"]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1].set_title(\"Média de Intensidade por Imagem\",\n",
    "                  fontsize=11, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Intensidade média\", fontsize=9)\n",
    "axes[1].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "# Boxplot do desvio padrão\n",
    "data_stds = [stds_normal, stds_pneumonia]\n",
    "bp2 = axes[2].boxplot(data_stds, labels=[\"Normal\", \"Pneumonia\"],\n",
    "                      patch_artist=True, notch=True,\n",
    "                      medianprops=dict(color=\"black\", linewidth=2))\n",
    "for patch, color in zip(bp2[\"boxes\"], [\"#5B8DB8\", \"#C0504D\"]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[2].set_title(\"Desvio Padrão de Intensidade por Imagem\\n(proxy de heterogeneidade textural)\",\n",
    "                  fontsize=11, fontweight=\"bold\")\n",
    "axes[2].set_ylabel(\"Desvio padrão\", fontsize=9)\n",
    "axes[2].spines[[\"top\",\"right\"]].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Análise de Intensidade de Pixels por Classe\",\n",
    "             fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "fig.text(0.5, -0.06,\n",
    "         \"→ Diferenças de intensidade e textura entre classes confirmam que \"\n",
    "         \"CNNs são adequadas: capturam padrões espaciais locais hierárquicos \"\n",
    "         \"que separam as classes.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_intensidade_pixels.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 6. Galeria Visual — Padrões Diagnósticos por Classe\n",
    "\n",
    "Visualização comparativa de exemplos representativos de cada classe,\n",
    "ilustrando os padrões visuais que os modelos devem aprender.\n",
    "\n",
    "**O que observar:**\n",
    "- **Normal**: campos pulmonares translúcidos, costelas bem definidas, sem opacidades\n",
    "- **Pneumonia**: consolidações (regiões opacas/brancas), infiltrados, assimetrias\n",
    "\n",
    "Esses padrões são espacialmente distribuídos e de textura variável,\n",
    "justificando o uso de CNNs com filtros hierárquicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(16, 7))\n",
    "\n",
    "normal_samples    = df[df[\"label\"] == 0].sample(5, random_state=42)\n",
    "pneumonia_samples = df[df[\"label\"] == 1].sample(5, random_state=42)\n",
    "\n",
    "for i, (_, row) in enumerate(normal_samples.iterrows()):\n",
    "    img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "    axes[0, i].imshow(img, cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"Normal\", fontsize=10, color=\"#5B8DB8\", fontweight=\"bold\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "for i, (_, row) in enumerate(pneumonia_samples.iterrows()):\n",
    "    img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "    axes[1, i].imshow(img, cmap=\"gray\")\n",
    "    axes[1, i].set_title(f\"Pneumonia\", fontsize=10, color=\"#C0504D\", fontweight=\"bold\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Galeria Visual — Exemplos Representativos por Classe\",\n",
    "             fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "# Anotações de linha\n",
    "fig.text(0.01, 0.73, \"Normal\", va=\"center\", ha=\"left\", rotation=90,\n",
    "         fontsize=12, color=\"#5B8DB8\", fontweight=\"bold\")\n",
    "fig.text(0.01, 0.27, \"Pneumonia\", va=\"center\", ha=\"left\", rotation=90,\n",
    "         fontsize=12, color=\"#C0504D\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_galeria_visual.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 7. Análise de Artefatos Periféricos — Motivação para CenterCrop\n",
    "\n",
    "Imagens de raio-X clínicas frequentemente contêm:\n",
    "- Bordas escuras (padding do detector)\n",
    "- Marcações hospitalares (texto, logos)\n",
    "- Dispositivos médicos (drenos, cabos de monitor)\n",
    "\n",
    "O CenterCrop de 90% do resize remove sistematicamente\n",
    "as bordas externas, reduzindo o risco de o modelo\n",
    "aprender esses artefatos como features discriminativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformações para demonstração\n",
    "resize_only = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "with_centercrop = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(int(224 * 0.9)),  # 201px\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "sample_paths = df.sample(4, random_state=7)[\"path\"].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "\n",
    "for i, path in enumerate(sample_paths):\n",
    "    img_pil = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    # Resize apenas\n",
    "    img_resize = transforms.Compose([transforms.Resize((224, 224))])(img_pil)\n",
    "    axes[0, i].imshow(img_resize, cmap=\"gray\")\n",
    "    axes[0, i].set_title(\"Resize (224×224)\", fontsize=9)\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Com CenterCrop\n",
    "    img_crop = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop(int(224 * 0.9))\n",
    "    ])(img_pil)\n",
    "    axes[1, i].imshow(img_crop, cmap=\"gray\")\n",
    "    axes[1, i].set_title(\"+ CenterCrop (90%)\", fontsize=9, color=\"#7DBE7D\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "    # Destacar bordas removidas\n",
    "    for ax in [axes[0, i], axes[1, i]]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "\n",
    "fig.suptitle(\"Efeito do CenterCrop — Remoção de Bordas e Artefatos Periféricos\",\n",
    "             fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "fig.text(0.5, -0.02,\n",
    "         \"→ CenterCrop de 90% remove regiões periféricas com artefatos \"\n",
    "         \"(bordas escuras, marcações) sem perda de informação pulmonar central.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_centercrop.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "## 8. Análise de Data Augmentation — Motivação para H2\n",
    "\n",
    "Visualização comparativa entre o augmentation leve (Baseline)\n",
    "e o augmentation forte (H2), aplicados sobre a mesma imagem.\n",
    "\n",
    "**Hipótese 2:** augmentation mais intenso atuaria como regularização,\n",
    "reduzindo sobreajuste e melhorando generalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_light = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(int(224 * 0.9)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.RandomRotation(5),\n",
    "])\n",
    "\n",
    "aug_strong = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(int(224 * 0.9)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "])\n",
    "\n",
    "# Usar a mesma imagem para comparação\n",
    "sample_path = df[df[\"label\"] == 1].sample(1, random_state=10)[\"path\"].values[0]\n",
    "original    = Image.open(sample_path).convert(\"RGB\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 7))\n",
    "\n",
    "# Linha 0: Augmentation Leve\n",
    "axes[0, 0].imshow(original, cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Original\", fontsize=9, fontweight=\"bold\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "for j in range(1, 5):\n",
    "    aug_img = aug_light(original)\n",
    "    axes[0, j].imshow(aug_img, cmap=\"gray\")\n",
    "    axes[0, j].set_title(f\"Leve #{j}\", fontsize=9, color=\"#5B8DB8\")\n",
    "    axes[0, j].axis(\"off\")\n",
    "\n",
    "# Linha 1: Augmentation Forte\n",
    "axes[1, 0].imshow(original, cmap=\"gray\")\n",
    "axes[1, 0].set_title(\"Original\", fontsize=9, fontweight=\"bold\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "for j in range(1, 5):\n",
    "    aug_img = aug_strong(original)\n",
    "    axes[1, j].imshow(aug_img, cmap=\"gray\")\n",
    "    axes[1, j].set_title(f\"Forte #{j}\", fontsize=9, color=\"#C0504D\")\n",
    "    axes[1, j].axis(\"off\")\n",
    "\n",
    "fig.text(0.01, 0.73, \"Aug. Leve\", va=\"center\", ha=\"left\", rotation=90,\n",
    "         fontsize=11, color=\"#5B8DB8\", fontweight=\"bold\")\n",
    "fig.text(0.01, 0.27, \"Aug. Forte\", va=\"center\", ha=\"left\", rotation=90,\n",
    "         fontsize=11, color=\"#C0504D\", fontweight=\"bold\")\n",
    "\n",
    "fig.suptitle(\"Comparação Visual: Augmentation Leve vs Forte — Motivação para H2\",\n",
    "             fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "fig.text(0.5, -0.02,\n",
    "         \"→ O augmentation forte altera mais agressivamente a geometria da imagem. \"\n",
    "         \"Hipótese 2 testa se isso melhora a generalização sem distorcer padrões patológicos.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_augmentation.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3",
   "metadata": {},
   "source": [
    "## 9. Variabilidade Visual Intra-Classe — Motivação para Transfer Learning e H1\n",
    "\n",
    "A variabilidade dentro de cada classe (diferentes pacientes,\n",
    "idades, posicionamentos) impõe desafios adicionais ao modelo.\n",
    "\n",
    "- **Alta variabilidade intra-classe** → Transfer Learning é essencial\n",
    "  (representações genéricas do ImageNet aceleram convergência)\n",
    "- **Padrões sutis em alguns casos** → Motivou testar DenseNet121 (H1),\n",
    "  que propaga features de forma mais densa entre camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular variância média dentro de cada classe\n",
    "print(\"Calculando variância intra-classe...\")\n",
    "\n",
    "def get_image_vector(path, size=64):\n",
    "    \"\"\"Retorna imagem como vetor normalizado para comparação.\"\"\"\n",
    "    try:\n",
    "        return np.array(Image.open(path).convert(\"L\").resize((size, size))).flatten() / 255.0\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "n_sample = 100\n",
    "vecs_normal    = [v for path in df[df[\"label\"]==0].sample(n_sample, random_state=42)[\"path\"]\n",
    "                  if (v := get_image_vector(path)) is not None]\n",
    "vecs_pneumonia = [v for path in df[df[\"label\"]==1].sample(n_sample, random_state=42)[\"path\"]\n",
    "                  if (v := get_image_vector(path)) is not None]\n",
    "\n",
    "var_normal    = np.var(np.stack(vecs_normal),    axis=0).mean()\n",
    "var_pneumonia = np.var(np.stack(vecs_pneumonia), axis=0).mean()\n",
    "\n",
    "print(f\"Variância intra-classe Normal:    {var_normal:.5f}\")\n",
    "print(f\"Variância intra-classe Pneumonia: {var_pneumonia:.5f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Mapa de variância pixel-a-pixel\n",
    "var_map_normal    = np.var(np.stack(vecs_normal),    axis=0).reshape(64, 64)\n",
    "var_map_pneumonia = np.var(np.stack(vecs_pneumonia), axis=0).reshape(64, 64)\n",
    "\n",
    "im0 = axes[0].imshow(var_map_normal, cmap=\"hot\", vmin=0)\n",
    "axes[0].set_title(f\"Variância Pixel-a-Pixel — Normal\\n(média={var_normal:.4f})\",\n",
    "                  fontsize=11, fontweight=\"bold\", color=\"#5B8DB8\")\n",
    "axes[0].axis(\"off\")\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046)\n",
    "\n",
    "im1 = axes[1].imshow(var_map_pneumonia, cmap=\"hot\", vmin=0)\n",
    "axes[1].set_title(f\"Variância Pixel-a-Pixel — Pneumonia\\n(média={var_pneumonia:.4f})\",\n",
    "                  fontsize=11, fontweight=\"bold\", color=\"#C0504D\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046)\n",
    "\n",
    "fig.suptitle(\"Variabilidade Visual Intra-Classe — Motivação para Transfer Learning\",\n",
    "             fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "fig.text(0.5, -0.06,\n",
    "         \"→ Alta variabilidade intra-classe indica que o modelo precisa de \"\n",
    "         \"representações robustas — justificando transfer learning em vez de treino do zero.\",\n",
    "         ha=\"center\", fontsize=10, style=\"italic\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"#FFF3CD\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_variabilidade_intraclasse.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## 10. Síntese da EDA — Mapa de Decisões\n",
    "\n",
    "Figura consolidada conectando cada achado à sua decisão metodológica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Dados da tabela\n",
    "table_data = [\n",
    "    [\"Desbalanceamento de classes (~2.7x)\",\n",
    "     \"Class Weighting na loss function\",\n",
    "     \"H3 — Class Weight\"],\n",
    "    [\"Dataset moderado (~5k imagens)\",\n",
    "     \"Transfer Learning (ImageNet)\",\n",
    "     \"Baseline, H1, H2, H3\"],\n",
    "    [\"Alta variabilidade de dimensões\",\n",
    "     \"Resize padronizado 224×224\",\n",
    "     \"Todos os experimentos\"],\n",
    "    [\"Artefatos nas bordas periféricas\",\n",
    "     \"CenterCrop 90% após resize\",\n",
    "     \"Todos os experimentos\"],\n",
    "    [\"Padrões espaciais/texturais nas classes\",\n",
    "     \"CNN como arquitetura base\",\n",
    "     \"Todos os experimentos\"],\n",
    "    [\"Variabilidade intra-classe alta\",\n",
    "     \"Augmentation leve como regularização\",\n",
    "     \"Baseline, H1, H3\"],\n",
    "    [\"Hipótese: aug. forte melhora generalização\",\n",
    "     \"Augmentation forte (rotação ±15°, jitter)\",\n",
    "     \"H2 — Strong Aug\"],\n",
    "    [\"Hipótese: arquitetura diferente capta\\npadrões mais sutis\",\n",
    "     \"DenseNet121 (dense connections)\",\n",
    "     \"H1 — DenseNet121\"],\n",
    "]\n",
    "\n",
    "col_labels = [\"Achado do EDA\", \"Decisão Metodológica\", \"Experimento Relacionado\"]\n",
    "col_colors = [[\"#2C3E50\"] * 3]\n",
    "\n",
    "row_colors_map = [\n",
    "    \"#FADADD\",  # H3 - destaque\n",
    "    \"#EAF2FB\",\n",
    "    \"#EAF2FB\",\n",
    "    \"#EAF2FB\",\n",
    "    \"#EAF2FB\",\n",
    "    \"#EAF2FB\",\n",
    "    \"#FEF9E7\",\n",
    "    \"#FEF9E7\",\n",
    "]\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=col_labels,\n",
    "    loc=\"center\",\n",
    "    cellLoc=\"left\"\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.2)\n",
    "\n",
    "# Estilo do header\n",
    "for col in range(3):\n",
    "    table[0, col].set_facecolor(\"#2C3E50\")\n",
    "    table[0, col].set_text_props(color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# Cores das linhas\n",
    "for row_idx, color in enumerate(row_colors_map, start=1):\n",
    "    for col in range(3):\n",
    "        table[row_idx, col].set_facecolor(color)\n",
    "\n",
    "# Negrito na linha do H3\n",
    "for col in range(3):\n",
    "    table[1, col].set_text_props(fontweight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Síntese da EDA — Mapa de Achados e Decisões Metodológicas\",\n",
    "             fontsize=13, fontweight=\"bold\", pad=20)\n",
    "\n",
    "# Legenda\n",
    "patches = [\n",
    "    mpatches.Patch(color=\"#FADADD\", label=\"Motivação principal para modelo recomendado (H3)\"),\n",
    "    mpatches.Patch(color=\"#FEF9E7\", label=\"Hipóteses testadas (H1, H2)\"),\n",
    "    mpatches.Patch(color=\"#EAF2FB\", label=\"Decisões de pré-processamento (todos)\"),\n",
    "]\n",
    "ax.legend(handles=patches, loc=\"lower center\",\n",
    "          bbox_to_anchor=(0.5, -0.08), ncol=3, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(figures_dir, \"eda_mapa_decisoes.png\")\n",
    "plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Salvo em:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5b6c7",
   "metadata": {},
   "source": [
    "## 11. Conclusão da EDA\n",
    "\n",
    "A análise exploratória revelou quatro características fundamentais\n",
    "do conjunto de dados que guiaram as escolhas metodológicas:\n",
    "\n",
    "**1. Desbalanceamento de classes (~2.7x):** a predominância de casos\n",
    "de Pneumonia impõe viés natural ao modelo. A ponderação de classes\n",
    "(H3) é a intervenção mais direta para corrigir esse efeito,\n",
    "aumentando a penalidade por erros na classe minoritária (Normal).\n",
    "\n",
    "**2. Tamanho moderado do dataset (~5.2k imagens):** insuficiente\n",
    "para treinar arquiteturas profundas do zero com estabilidade.\n",
    "O transfer learning com pesos do ImageNet reduz o risco de\n",
    "sobreajuste e acelera a convergência.\n",
    "\n",
    "**3. Variabilidade de dimensões e artefatos periféricos:**\n",
    "exige padronização cuidadosa via Resize + CenterCrop,\n",
    "garantindo que o modelo processe regiões anatomicamente\n",
    "relevantes e não bordas ou marcações hospitalares.\n",
    "\n",
    "**4. Padrões espaciais e texturais discriminativos:**\n",
    "consolidações, infiltrados e opacidades são padrões\n",
    "locais e hierárquicos — exatamente o que filtros\n",
    "convolucionais são projetados para capturar.\n",
    "\n",
    "Esses achados fundamentam empiricamente todas as hipóteses\n",
    "experimentais e as decisões de pré-processamento adotadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Figuras da EDA geradas em:\", figures_dir)\n",
    "figuras = [\n",
    "    \"eda_distribuicao_classes.png\",\n",
    "    \"eda_dimensoes.png\",\n",
    "    \"eda_intensidade_pixels.png\",\n",
    "    \"eda_galeria_visual.png\",\n",
    "    \"eda_centercrop.png\",\n",
    "    \"eda_augmentation.png\",\n",
    "    \"eda_variabilidade_intraclasse.png\",\n",
    "    \"eda_mapa_decisoes.png\",\n",
    "]\n",
    "for f in figuras:\n",
    "    print(\" •\", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {"name": "ipython", "version": 3},
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
