{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 07 — Interpretabilidade: Grad-CAM\n",
    "\n",
    "Projeto: Classificação de Pneumonia em Raio-X  \n",
    "\n",
    "Diretório raiz esperado:\n",
    "\n",
    "C:/projects/xray-project/\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Aplicar Grad-CAM (Gradient-weighted Class Activation Mapping) para\n",
    "visualizar as regiões das imagens de raio-X que mais influenciam\n",
    "as decisões dos modelos treinados.\n",
    "\n",
    "A análise é realizada em dois modelos:\n",
    "- ResNet18 Baseline (resnet18_light_noCW.pt)\n",
    "- ResNet18 Class Weight (resnet18_light_CW.pt) — modelo defendido\n",
    "\n",
    "Para cada modelo, são analisados:\n",
    "- Verdadeiros Positivos (TP): Pneumonia corretamente identificada\n",
    "- Verdadeiros Negativos (TN): Normal corretamente identificado\n",
    "- Falsos Negativos (FN): Pneumonia classificada como Normal\n",
    "- Falsos Positivos (FP): Normal classificado como Pneumonia\n",
    "\n",
    "Arquivos gerados:\n",
    "- outputs/figures/gradcam/baseline_TP.png\n",
    "- outputs/figures/gradcam/baseline_FN.png\n",
    "- outputs/figures/gradcam/cw_TP.png\n",
    "- outputs/figures/gradcam/cw_FN.png\n",
    "- outputs/figures/gradcam/comparacao_modelos.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from model import get_model\n",
    "from transforms import get_transforms\n",
    "from dataset import XRayDataset\n",
    "from utils import set_seed, create_directories\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, gradcam_dir = create_directories(PROJECT_ROOT)\n",
    "print(\"Grad-CAM output dir:\", gradcam_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 2. Implementação do Grad-CAM\n",
    "\n",
    "O Grad-CAM utiliza os gradientes da classe alvo em relação aos\n",
    "mapas de ativação da última camada convolucional para gerar um\n",
    "mapa de calor (heatmap) que destaca as regiões mais relevantes\n",
    "para a decisão do modelo.\n",
    "\n",
    "Referência: Selvaraju et al. (2017), \"Grad-CAM: Visual Explanations\n",
    "from Deep Networks via Gradient-based Localization\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Implementação de Grad-CAM compatível com ResNet18 e DenseNet121.\n",
    "\n",
    "    Parâmetros:\n",
    "        model: modelo PyTorch já carregado\n",
    "        target_layer: camada convolucional alvo para extração dos gradientes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        \"\"\"Registra hooks para capturar ativações e gradientes.\"\"\"\n",
    "\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor, target_class=None):\n",
    "        \"\"\"\n",
    "        Gera o heatmap Grad-CAM para a imagem de entrada.\n",
    "\n",
    "        Parâmetros:\n",
    "            input_tensor: tensor da imagem (1, C, H, W)\n",
    "            target_class: classe alvo (None → usa a predita)\n",
    "\n",
    "        Retorno:\n",
    "            heatmap (np.array): mapa de calor normalizado [0, 1]\n",
    "            pred_class (int): classe predita\n",
    "            pred_prob (float): probabilidade da classe positiva\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        input_tensor = input_tensor.requires_grad_(True)\n",
    "\n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        pred_prob = probs[0, 1].item()  # prob da classe Pneumonia\n",
    "\n",
    "        if target_class is None:\n",
    "            target_class = pred_class\n",
    "\n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        score = output[0, target_class]\n",
    "        score.backward()\n",
    "\n",
    "        # Gradientes e ativações\n",
    "        gradients = self.gradients        # (1, C, H, W)\n",
    "        activations = self.activations    # (1, C, H, W)\n",
    "\n",
    "        # Pesos: média global dos gradientes por canal\n",
    "        weights = gradients.mean(dim=(2, 3), keepdim=True)  # (1, C, 1, 1)\n",
    "\n",
    "        # Mapa de ativação ponderado\n",
    "        cam = (weights * activations).sum(dim=1).squeeze()  # (H, W)\n",
    "        cam = torch.relu(cam)\n",
    "\n",
    "        # Normalização\n",
    "        cam = cam.cpu().numpy()\n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "\n",
    "        return cam, pred_class, pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 3. Funções Auxiliares de Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_heatmap(original_img_pil, cam, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Sobrepõe o heatmap Grad-CAM na imagem original.\n",
    "\n",
    "    Parâmetros:\n",
    "        original_img_pil: imagem PIL original (sem normalização)\n",
    "        cam: heatmap numpy [0, 1]\n",
    "        alpha: intensidade da sobreposição\n",
    "\n",
    "    Retorno:\n",
    "        overlay: imagem numpy com heatmap sobreposto (H, W, 3)\n",
    "    \"\"\"\n",
    "    # Converter para numpy RGB\n",
    "    img_np = np.array(original_img_pil.convert(\"RGB\"))\n",
    "    h, w = img_np.shape[:2]\n",
    "\n",
    "    # Redimensionar heatmap para o tamanho da imagem original\n",
    "    cam_resized = cv2.resize(cam, (w, h))\n",
    "\n",
    "    # Aplicar colormap JET\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        np.uint8(255 * cam_resized),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Blend\n",
    "    overlay = (alpha * heatmap + (1 - alpha) * img_np).astype(np.uint8)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def get_label_name(label):\n",
    "    return \"Pneumonia\" if label == 1 else \"Normal\"\n",
    "\n",
    "\n",
    "def get_pred_name(pred_class):\n",
    "    return \"Pneumonia\" if pred_class == 1 else \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradcam_grid(samples, gradcam, val_transform, title, save_path, n_cols=4):\n",
    "    \"\"\"\n",
    "    Plota uma grade de imagens com Grad-CAM sobreposto.\n",
    "\n",
    "    Cada coluna mostra: Imagem Original | Grad-CAM\n",
    "\n",
    "    Parâmetros:\n",
    "        samples: lista de dicts com 'path', 'label'\n",
    "        gradcam: instância do GradCAM já configurada\n",
    "        val_transform: transformação de validação\n",
    "        title: título geral da figura\n",
    "        save_path: caminho para salvar\n",
    "        n_cols: número de exemplos por linha\n",
    "    \"\"\"\n",
    "    n = len(samples)\n",
    "    fig, axes = plt.subplots(n, 2, figsize=(10, 4.5 * n))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle(title, fontsize=15, fontweight='bold', y=1.01)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        path = sample[\"path\"]\n",
    "        true_label = sample[\"label\"]\n",
    "\n",
    "        # Imagem original (sem transforms)\n",
    "        original_pil = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        # Tensor para o modelo\n",
    "        tensor = val_transform(original_pil).unsqueeze(0)\n",
    "\n",
    "        # Grad-CAM\n",
    "        cam, pred_class, pred_prob = gradcam.generate(tensor)\n",
    "\n",
    "        # Overlay\n",
    "        overlay = overlay_heatmap(original_pil, cam, alpha=0.4)\n",
    "\n",
    "        # Determinar cor do título\n",
    "        correct = (pred_class == true_label)\n",
    "        color = \"green\" if correct else \"red\"\n",
    "\n",
    "        # Plot original\n",
    "        axes[i][0].imshow(original_pil, cmap=\"gray\")\n",
    "        axes[i][0].set_title(\n",
    "            f\"Original\\nReal: {get_label_name(true_label)}\",\n",
    "            fontsize=11\n",
    "        )\n",
    "        axes[i][0].axis(\"off\")\n",
    "\n",
    "        # Plot Grad-CAM\n",
    "        axes[i][1].imshow(overlay)\n",
    "        axes[i][1].set_title(\n",
    "            f\"Grad-CAM\\nPredito: {get_pred_name(pred_class)} (p={pred_prob:.2f})\",\n",
    "            fontsize=11,\n",
    "            color=color\n",
    "        )\n",
    "        axes[i][1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 4. Carregamento dos Dados de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = os.path.join(PROJECT_ROOT, \"data\", \"metadata\")\n",
    "val_df = pd.read_csv(os.path.join(metadata_dir, \"val_split.csv\"))\n",
    "\n",
    "print(f\"Validação: {len(val_df)} imagens\")\n",
    "print(f\"Normal:    {(val_df['label'] == 0).sum()}\")\n",
    "print(f\"Pneumonia: {(val_df['label'] == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_transform = get_transforms(img_size=224, augmentation=\"light\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 5. Função de Predição em Lote\n",
    "\n",
    "Roda o modelo em todo o conjunto de validação para identificar\n",
    "TPs, TNs, FPs e FNs de forma sistemática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(model, val_df, val_transform, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Roda o modelo em toda a validação e retorna um DataFrame\n",
    "    com os resultados por imagem.\n",
    "\n",
    "    Retorno:\n",
    "        results_df com colunas: path, label, pred_class, pred_prob\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, row in val_df.iterrows():\n",
    "            img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "            tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(tensor)\n",
    "            prob = torch.softmax(output, dim=1)[0, 1].item()\n",
    "            pred = 1 if prob >= threshold else 0\n",
    "\n",
    "            results.append({\n",
    "                \"path\": row[\"path\"],\n",
    "                \"label\": row[\"label\"],\n",
    "                \"pred_class\": pred,\n",
    "                \"pred_prob\": prob\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def sample_cases(results_df, n=3):\n",
    "    \"\"\"\n",
    "    Seleciona n exemplos aleatórios de cada categoria\n",
    "    (TP, TN, FP, FN).\n",
    "    \"\"\"\n",
    "    tp = results_df[(results_df[\"label\"] == 1) & (results_df[\"pred_class\"] == 1)].sample(min(n, len(results_df[(results_df[\"label\"] == 1) & (results_df[\"pred_class\"] == 1)])), random_state=42)\n",
    "    tn = results_df[(results_df[\"label\"] == 0) & (results_df[\"pred_class\"] == 0)].sample(min(n, len(results_df[(results_df[\"label\"] == 0) & (results_df[\"pred_class\"] == 0)])), random_state=42)\n",
    "    fp = results_df[(results_df[\"label\"] == 0) & (results_df[\"pred_class\"] == 1)]\n",
    "    fn = results_df[(results_df[\"label\"] == 1) & (results_df[\"pred_class\"] == 0)]\n",
    "\n",
    "    # Para FP e FN, pegar todos se houver menos que n\n",
    "    fp = fp.sample(min(n, len(fp)), random_state=42) if len(fp) > 0 else fp\n",
    "    fn = fn.sample(min(n, len(fn)), random_state=42) if len(fn) > 0 else fn\n",
    "\n",
    "    print(f\"TP: {len(tp)} | TN: {len(tn)} | FP: {len(fp)} | FN: {len(fn)}\")\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 6. Grad-CAM — Baseline (ResNet18 sem Class Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models_dir = os.path.join(PROJECT_ROOT, \"models\")\n",
    "\n",
    "# Carregar modelo Baseline\n",
    "baseline_model, baseline_target_layer = get_model(model_name=\"resnet18\")\n",
    "baseline_model.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(models_dir, \"resnet18_light_noCW.pt\"),\n",
    "        map_location=device\n",
    "    )\n",
    ")\n",
    "baseline_model = baseline_model.to(device)\n",
    "baseline_model.eval()\n",
    "\n",
    "print(\"Baseline carregado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_baseline = GradCAM(baseline_model, baseline_target_layer)\n",
    "\n",
    "print(\"Rodando predições no conjunto de validação...\")\n",
    "results_baseline = predict_all(baseline_model, val_df, val_transform, device)\n",
    "\n",
    "tp_b, tn_b, fp_b, fn_b = sample_cases(results_baseline, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verdadeiros Positivos (Baseline) ---\n",
    "plot_gradcam_grid(\n",
    "    samples=tp_b.to_dict(\"records\"),\n",
    "    gradcam=gradcam_baseline,\n",
    "    val_transform=val_transform,\n",
    "    title=\"Baseline (ResNet18) — Verdadeiros Positivos (TP)\\nPneumonia corretamente identificada\",\n",
    "    save_path=os.path.join(gradcam_dir, \"baseline_TP.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Falsos Negativos (Baseline) ---\n",
    "# Casos críticos: pneumonia não detectada → risco clínico\n",
    "if len(fn_b) > 0:\n",
    "    plot_gradcam_grid(\n",
    "        samples=fn_b.to_dict(\"records\"),\n",
    "        gradcam=gradcam_baseline,\n",
    "        val_transform=val_transform,\n",
    "        title=\"Baseline (ResNet18) — Falsos Negativos (FN)\\nPneumonia classificada como Normal\",\n",
    "        save_path=os.path.join(gradcam_dir, \"baseline_FN.png\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Nenhum FN encontrado para o Baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verdadeiros Negativos (Baseline) ---\n",
    "plot_gradcam_grid(\n",
    "    samples=tn_b.to_dict(\"records\"),\n",
    "    gradcam=gradcam_baseline,\n",
    "    val_transform=val_transform,\n",
    "    title=\"Baseline (ResNet18) — Verdadeiros Negativos (TN)\\nNormal corretamente identificado\",\n",
    "    save_path=os.path.join(gradcam_dir, \"baseline_TN.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## 7. Grad-CAM — Class Weight (ResNet18 com Ponderação de Classes)\n",
    "\n",
    "Este modelo é o defendido no relatório por apresentar\n",
    "menor número de Falsos Negativos (5 vs 16 do Baseline),\n",
    "métrica de maior relevância clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo Class Weight\n",
    "cw_model, cw_target_layer = get_model(model_name=\"resnet18\")\n",
    "cw_model.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(models_dir, \"resnet18_light_CW.pt\"),\n",
    "        map_location=device\n",
    "    )\n",
    ")\n",
    "cw_model = cw_model.to(device)\n",
    "cw_model.eval()\n",
    "\n",
    "print(\"Class Weight carregado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_cw = GradCAM(cw_model, cw_target_layer)\n",
    "\n",
    "print(\"Rodando predições no conjunto de validação...\")\n",
    "results_cw = predict_all(cw_model, val_df, val_transform, device)\n",
    "\n",
    "tp_cw, tn_cw, fp_cw, fn_cw = sample_cases(results_cw, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verdadeiros Positivos (CW) ---\n",
    "plot_gradcam_grid(\n",
    "    samples=tp_cw.to_dict(\"records\"),\n",
    "    gradcam=gradcam_cw,\n",
    "    val_transform=val_transform,\n",
    "    title=\"Class Weight (ResNet18) — Verdadeiros Positivos (TP)\\nPneumonia corretamente identificada\",\n",
    "    save_path=os.path.join(gradcam_dir, \"cw_TP.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Falsos Negativos (CW) ---\n",
    "# Espera-se menos FNs do que no Baseline\n",
    "if len(fn_cw) > 0:\n",
    "    plot_gradcam_grid(\n",
    "        samples=fn_cw.to_dict(\"records\"),\n",
    "        gradcam=gradcam_cw,\n",
    "        val_transform=val_transform,\n",
    "        title=\"Class Weight (ResNet18) — Falsos Negativos (FN)\\nPneumonia classificada como Normal\",\n",
    "        save_path=os.path.join(gradcam_dir, \"cw_FN.png\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Nenhum FN encontrado para o modelo Class Weight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verdadeiros Negativos (CW) ---\n",
    "plot_gradcam_grid(\n",
    "    samples=tn_cw.to_dict(\"records\"),\n",
    "    gradcam=gradcam_cw,\n",
    "    val_transform=val_transform,\n",
    "    title=\"Class Weight (ResNet18) — Verdadeiros Negativos (TN)\\nNormal corretamente identificado\",\n",
    "    save_path=os.path.join(gradcam_dir, \"cw_TN.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1",
   "metadata": {},
   "source": [
    "## 8. Comparação Direta: Baseline vs Class Weight\n",
    "\n",
    "Visualização lado a lado das mesmas imagens nos dois modelos.\n",
    "\n",
    "Objetivo: verificar se o modelo Class Weight foca em regiões\n",
    "anatomicamente mais plausíveis (regiões pulmonares)\n",
    "comparado ao Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(samples, gradcam_a, gradcam_b, label_a, label_b,\n",
    "                    val_transform, title, save_path):\n",
    "    \"\"\"\n",
    "    Compara dois modelos lado a lado nas mesmas imagens.\n",
    "\n",
    "    Colunas: Original | Grad-CAM Modelo A | Grad-CAM Modelo B\n",
    "    \"\"\"\n",
    "    n = len(samples)\n",
    "    fig, axes = plt.subplots(n, 3, figsize=(14, 4.5 * n))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=1.01)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        path = sample[\"path\"]\n",
    "        true_label = sample[\"label\"]\n",
    "\n",
    "        original_pil = Image.open(path).convert(\"RGB\")\n",
    "        tensor = val_transform(original_pil).unsqueeze(0)\n",
    "\n",
    "        # Grad-CAM dos dois modelos\n",
    "        cam_a, pred_a, prob_a = gradcam_a.generate(tensor)\n",
    "        cam_b, pred_b, prob_b = gradcam_b.generate(tensor)\n",
    "\n",
    "        overlay_a = overlay_heatmap(original_pil, cam_a)\n",
    "        overlay_b = overlay_heatmap(original_pil, cam_b)\n",
    "\n",
    "        # Original\n",
    "        axes[i][0].imshow(original_pil, cmap=\"gray\")\n",
    "        axes[i][0].set_title(f\"Original\\nReal: {get_label_name(true_label)}\", fontsize=10)\n",
    "        axes[i][0].axis(\"off\")\n",
    "\n",
    "        # Modelo A\n",
    "        color_a = \"green\" if pred_a == true_label else \"red\"\n",
    "        axes[i][1].imshow(overlay_a)\n",
    "        axes[i][1].set_title(\n",
    "            f\"{label_a}\\nPredito: {get_pred_name(pred_a)} (p={prob_a:.2f})\",\n",
    "            fontsize=10, color=color_a\n",
    "        )\n",
    "        axes[i][1].axis(\"off\")\n",
    "\n",
    "        # Modelo B\n",
    "        color_b = \"green\" if pred_b == true_label else \"red\"\n",
    "        axes[i][2].imshow(overlay_b)\n",
    "        axes[i][2].set_title(\n",
    "            f\"{label_b}\\nPredito: {get_pred_name(pred_b)} (p={prob_b:.2f})\",\n",
    "            fontsize=10, color=color_b\n",
    "        )\n",
    "        axes[i][2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar imagens de pneumonia presentes nos dois conjuntos\n",
    "# para comparação (FNs do Baseline que o CW acertou)\n",
    "\n",
    "# Merge para identificar casos onde Baseline errou e CW acertou\n",
    "merged = results_baseline.merge(\n",
    "    results_cw[[\"path\", \"pred_class\", \"pred_prob\"]],\n",
    "    on=\"path\",\n",
    "    suffixes=(\"_baseline\", \"_cw\")\n",
    ")\n",
    "\n",
    "# Baseline FN + CW TP: casos clinicamente relevantes\n",
    "interesting = merged[\n",
    "    (merged[\"label\"] == 1) &\n",
    "    (merged[\"pred_class_baseline\"] == 0) &\n",
    "    (merged[\"pred_class_cw\"] == 1)\n",
    "]\n",
    "\n",
    "print(f\"Casos onde Baseline errou e CW acertou: {len(interesting)}\")\n",
    "\n",
    "if len(interesting) >= 1:\n",
    "    comparison_samples = interesting.head(3)[[\"path\", \"label\"]].to_dict(\"records\")\n",
    "else:\n",
    "    # Fallback: usar TPs de pneumonia em geral\n",
    "    print(\"Usando TPs de pneumonia para comparação geral.\")\n",
    "    comparison_samples = tp_b.head(3)[[\"path\", \"label\"]].to_dict(\"records\")\n",
    "\n",
    "plot_comparison(\n",
    "    samples=comparison_samples,\n",
    "    gradcam_a=gradcam_baseline,\n",
    "    gradcam_b=gradcam_cw,\n",
    "    label_a=\"Baseline (ResNet18)\",\n",
    "    label_b=\"Class Weight (ResNet18)\",\n",
    "    val_transform=val_transform,\n",
    "    title=\"Comparação Grad-CAM\\nBaseline vs Class Weight — Casos de Pneumonia\",\n",
    "    save_path=os.path.join(gradcam_dir, \"comparacao_modelos.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "## 9. Resumo dos Resultados\n",
    "\n",
    "Tabela comparativa dos dois modelos analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_predictions(results_df, model_name):\n",
    "    tp = ((results_df[\"label\"] == 1) & (results_df[\"pred_class\"] == 1)).sum()\n",
    "    tn = ((results_df[\"label\"] == 0) & (results_df[\"pred_class\"] == 0)).sum()\n",
    "    fp = ((results_df[\"label\"] == 0) & (results_df[\"pred_class\"] == 1)).sum()\n",
    "    fn = ((results_df[\"label\"] == 1) & (results_df[\"pred_class\"] == 0)).sum()\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    accuracy = (tp + tn) / len(results_df)\n",
    "\n",
    "    print(f\"\\n{'='*45}\")\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"{'='*45}\")\n",
    "    print(f\"  TP (Pneumonia correta):  {tp}\")\n",
    "    print(f\"  TN (Normal correta):     {tn}\")\n",
    "    print(f\"  FP (Normal → Pneumonia): {fp}\")\n",
    "    print(f\"  FN (Pneumonia → Normal): {fn}  ← relevância clínica\")\n",
    "    print(f\"  Sensitivity (Recall):    {sensitivity:.4f}\")\n",
    "    print(f\"  Specificity:             {specificity:.4f}\")\n",
    "    print(f\"  Accuracy:                {accuracy:.4f}\")\n",
    "\n",
    "summarize_predictions(results_baseline, \"ResNet18 Baseline\")\n",
    "summarize_predictions(results_cw, \"ResNet18 Class Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f7",
   "metadata": {},
   "source": [
    "## 10. Interpretação dos Resultados\n",
    "\n",
    "### O que observar nos mapas Grad-CAM:\n",
    "\n",
    "**Regiões plausíveis (bom sinal):**\n",
    "- Concentração do calor nas regiões pulmonares\n",
    "- Foco em áreas de consolidação ou opacidade\n",
    "- Heatmap simétrico ou orientado para regiões anatômicas relevantes\n",
    "\n",
    "**Regiões problemáticas (sinal de atenção):**\n",
    "- Foco nas bordas da imagem (artefatos)\n",
    "- Ativação em regiões ósseas (costelas, clavícula) sem relação com pneumonia\n",
    "- Heatmap disperso sem foco claro\n",
    "\n",
    "### Por que o Class Weight é o modelo recomendado:\n",
    "\n",
    "Embora o Baseline apresente AUC ligeiramente superior no Kaggle\n",
    "(0.999029 vs 0.999154 — diferença marginal), o modelo com\n",
    "ponderação de classes demonstra **superioridade clínica** por:\n",
    "\n",
    "1. **Menor número de Falsos Negativos**: 5 vs 16 do Baseline.\n",
    "   Em contexto diagnóstico, um FN representa uma pneumonia\n",
    "   não detectada — potencial risco de vida.\n",
    "\n",
    "2. **Recall superior**: 0.9943 vs 0.9817, indicando maior\n",
    "   sensibilidade para casos positivos.\n",
    "\n",
    "3. **Comportamento mais calibrado**: o class weighting incentiva\n",
    "   o modelo a prestar mais atenção à classe minoritária,\n",
    "   o que pode refletir em ativações Grad-CAM mais focadas\n",
    "   nas regiões patológicas.\n",
    "\n",
    "A análise Grad-CAM permite verificar se essa diferença de\n",
    "sensibilidade está associada a uma estratégia de atenção\n",
    "anatomicamente mais coerente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
