{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421489e3",
   "metadata": {},
   "source": [
    "# Hipótese 3 — Class Weight\n",
    "## ResNet18 | Augmentation Leve | Com Class Weight\n",
    "\n",
    "Este experimento avalia se a aplicação de pesos na função de perda\n",
    "melhora a sensibilidade da classe Pneumonia, considerando o\n",
    "desbalanceamento do dataset.\n",
    "\n",
    "Mantemos:\n",
    "- Arquitetura ResNet18\n",
    "- Augmentation leve (baseline)\n",
    "- Mesmo split reprodutível\n",
    "- Mesma seed\n",
    "\n",
    "Alteramos:\n",
    "- Inclusão de class weights na CrossEntropyLoss\n",
    "\n",
    "Arquivos gerados:\n",
    "- models/resnet18_light_CW.pt\n",
    "- outputs/metrics/resnet18_light_CW.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af3e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\projects\\xray-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2914ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from dataset import XRayDataset\n",
    "from transforms import get_transforms\n",
    "from model import get_model\n",
    "from train_utils import train_model\n",
    "from utils import set_seed, create_directories, save_metrics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257db4b1",
   "metadata": {},
   "source": [
    "## Controle de Reprodutibilidade\n",
    "\n",
    "Fixamos a mesma seed utilizada nos experimentos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e386e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cddd9",
   "metadata": {},
   "source": [
    "## Preparação de Diretórios\n",
    "\n",
    "Garantimos que existam:\n",
    "- models/\n",
    "- outputs/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb3b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir, metrics_dir, _ = create_directories(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c56849",
   "metadata": {},
   "source": [
    "## Carregamento dos Splits\n",
    "\n",
    "Utilizamos exatamente os mesmos arquivos:\n",
    "- train_split.csv\n",
    "- val_split.csv\n",
    "\n",
    "Isso garante controle experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c39c1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 4093\n",
      "Validação: 1139\n"
     ]
    }
   ],
   "source": [
    "metadata_dir = os.path.join(PROJECT_ROOT, \"data\", \"metadata\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(metadata_dir, \"train_split.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(metadata_dir, \"val_split.csv\"))\n",
    "\n",
    "print(\"Treino:\", len(train_df))\n",
    "print(\"Validação:\", len(val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8317b1a",
   "metadata": {},
   "source": [
    "## Configuração\n",
    "\n",
    "Modelo: ResNet18  \n",
    "Augmentation: leve  \n",
    "Class Weight: ativado  \n",
    "Épocas: 10  \n",
    "Batch Size: 16  \n",
    "Learning Rate: 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdb774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet18\"\n",
    "augmentation = \"light\"\n",
    "use_class_weight = True\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2627b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = get_transforms(\n",
    "    img_size=224,\n",
    "    augmentation=augmentation\n",
    ")\n",
    "\n",
    "train_dataset = XRayDataset(train_df, transform=train_transform)\n",
    "val_dataset = XRayDataset(val_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8fd76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 1082\n",
      "Pneumonia: 3011\n",
      "Class Weights: tensor([1.8914, 0.6797])\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df[\"label\"].value_counts().sort_index()\n",
    "\n",
    "num_normal = class_counts[0]\n",
    "num_pneumonia = class_counts[1]\n",
    "\n",
    "print(\"Normal:\", num_normal)\n",
    "print(\"Pneumonia:\", num_pneumonia)\n",
    "\n",
    "total = num_normal + num_pneumonia\n",
    "\n",
    "weight_normal = total / (2 * num_normal)\n",
    "weight_pneumonia = total / (2 * num_pneumonia)\n",
    "\n",
    "class_weights = torch.tensor(\n",
    "    [weight_normal, weight_pneumonia],\n",
    "    dtype=torch.float\n",
    ").to(device)\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cc66b",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Arquitetura permanece ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02d706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model, target_layer = get_model(model_name=model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0c58d",
   "metadata": {},
   "source": [
    "## Função de Perda e Otimizador\n",
    "\n",
    "Ainda não utilizamos class weight nesta etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f82ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec4762",
   "metadata": {},
   "source": [
    "## Padrão de Nomeação\n",
    "\n",
    "modelo_augmentation_classweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed757b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = f\"{model_name}_{augmentation}_{'CW' if use_class_weight else 'noCW'}.pt\"\n",
    "metrics_filename = f\"{model_name}_{augmentation}_{'CW' if use_class_weight else 'noCW'}.pkl\"\n",
    "\n",
    "model_save_path = os.path.join(models_dir, model_filename)\n",
    "metrics_save_path = os.path.join(metrics_dir, metrics_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ba8d4",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "O loop de treinamento está implementado em src/train_utils.py.\n",
    "\n",
    "A cada época são exibidos:\n",
    "- Loss de treino\n",
    "- Loss de validação\n",
    "- ROC-AUC de validação\n",
    "- F1 de validação \n",
    "- Recall de validação\n",
    "- Prec. de validação\n",
    "\n",
    "O modelo conforme maior AUC é salvo automaticamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d2a5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 0.1469\n",
      "Val Loss:   0.1032\n",
      "Val AUC:    0.9975\n",
      "Val F1:     0.9766\n",
      "Val Recall: 0.9576\n",
      "Val Prec.:  0.9964\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0845\n",
      "Val Loss:   0.1376\n",
      "Val AUC:    0.9981\n",
      "Val F1:     0.9693\n",
      "Val Recall: 0.9427\n",
      "Val Prec.:  0.9976\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0552\n",
      "Val Loss:   0.1211\n",
      "Val AUC:    0.9979\n",
      "Val F1:     0.9729\n",
      "Val Recall: 0.9472\n",
      "Val Prec.:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0551\n",
      "Val Loss:   0.0375\n",
      "Val AUC:    0.9988\n",
      "Val F1:     0.9885\n",
      "Val Recall: 0.9885\n",
      "Val Prec.:  0.9885\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0383\n",
      "Val Loss:   0.0486\n",
      "Val AUC:    0.9991\n",
      "Val F1:     0.9879\n",
      "Val Recall: 0.9794\n",
      "Val Prec.:  0.9965\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0451\n",
      "Val Loss:   0.0313\n",
      "Val AUC:    0.9992\n",
      "Val F1:     0.9931\n",
      "Val Recall: 0.9943\n",
      "Val Prec.:  0.9920\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0343\n",
      "Val Loss:   0.0690\n",
      "Val AUC:    0.9987\n",
      "Val F1:     0.9820\n",
      "Val Recall: 0.9679\n",
      "Val Prec.:  0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0261\n",
      "Val Loss:   0.0488\n",
      "Val AUC:    0.9989\n",
      "Val F1:     0.9873\n",
      "Val Recall: 0.9805\n",
      "Val Prec.:  0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0268\n",
      "Val Loss:   0.0472\n",
      "Val AUC:    0.9985\n",
      "Val F1:     0.9879\n",
      "Val Recall: 0.9851\n",
      "Val Prec.:  0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0245\n",
      "Val Loss:   0.0408\n",
      "Val AUC:    0.9988\n",
      "Val F1:     0.9902\n",
      "Val Recall: 0.9874\n",
      "Val Prec.:  0.9931\n",
      "\n",
      "Melhor AUC obtida: 0.9991538672989039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "history, best_auc = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs,\n",
    "    model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e952dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: c:\\projects\\xray-project\\models\\resnet18_light_CW.pt\n",
      "Métricas salvas em: c:\\projects\\xray-project\\outputs\\metrics\\resnet18_light_CW.pkl\n",
      "Melhor AUC: 0.9991538672989039\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {\n",
    "    \"model_name\": model_name,\n",
    "    \"augmentation\": augmentation,\n",
    "    \"class_weight\": use_class_weight,\n",
    "    \"epochs\": epochs,\n",
    "    \"history\": history,\n",
    "    \"best_auc\": best_auc\n",
    "}\n",
    "\n",
    "save_metrics(metrics_dict, metrics_save_path)\n",
    "\n",
    "print(\"Modelo salvo em:\", model_save_path)\n",
    "print(\"Métricas salvas em:\", metrics_save_path)\n",
    "print(\"Melhor AUC:\", best_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
