{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421489e3",
   "metadata": {},
   "source": [
    "# Hipótese 3 — Class Weight\n",
    "## ResNet18 | Augmentation Leve | Com Class Weight\n",
    "\n",
    "Este experimento avalia se a aplicação de pesos na função de perda\n",
    "melhora a sensibilidade da classe Pneumonia, considerando o\n",
    "desbalanceamento do dataset.\n",
    "\n",
    "Mantemos:\n",
    "- Arquitetura ResNet18\n",
    "- Augmentation leve (baseline)\n",
    "- Mesmo split reprodutível\n",
    "- Mesma seed\n",
    "\n",
    "Alteramos:\n",
    "- Inclusão de class weights na CrossEntropyLoss\n",
    "\n",
    "Arquivos gerados:\n",
    "- models/resnet18_light_CW.pt\n",
    "- outputs/metrics/resnet18_light_CW.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af3e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\projects\\xray-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2914ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from dataset import XRayDataset\n",
    "from transforms import get_transforms\n",
    "from model import get_model\n",
    "from train_utils import train_model\n",
    "from utils import set_seed, create_directories, save_metrics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257db4b1",
   "metadata": {},
   "source": [
    "## Controle de Reprodutibilidade\n",
    "\n",
    "Fixamos a mesma seed utilizada nos experimentos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e386e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cddd9",
   "metadata": {},
   "source": [
    "## Preparação de Diretórios\n",
    "\n",
    "Garantimos que existam:\n",
    "- models/\n",
    "- outputs/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb3b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir, metrics_dir, _ = create_directories(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c56849",
   "metadata": {},
   "source": [
    "## Carregamento dos Splits\n",
    "\n",
    "Utilizamos exatamente os mesmos arquivos:\n",
    "- train_split.csv\n",
    "- val_split.csv\n",
    "\n",
    "Isso garante controle experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c39c1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 4093\n",
      "Validação: 1139\n"
     ]
    }
   ],
   "source": [
    "metadata_dir = os.path.join(PROJECT_ROOT, \"data\", \"metadata\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(metadata_dir, \"train_split.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(metadata_dir, \"val_split.csv\"))\n",
    "\n",
    "print(\"Treino:\", len(train_df))\n",
    "print(\"Validação:\", len(val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8317b1a",
   "metadata": {},
   "source": [
    "## Configuração\n",
    "\n",
    "Modelo: ResNet18  \n",
    "Augmentation: leve  \n",
    "Class Weight: ativado  \n",
    "Épocas: 10  \n",
    "Batch Size: 16  \n",
    "Learning Rate: 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccdb774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet18\"\n",
    "augmentation = \"light\"\n",
    "use_class_weight = True\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2627b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = get_transforms(\n",
    "    img_size=224,\n",
    "    augmentation=augmentation\n",
    ")\n",
    "\n",
    "train_dataset = XRayDataset(train_df, transform=train_transform)\n",
    "val_dataset = XRayDataset(val_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fd76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 1082\n",
      "Pneumonia: 3011\n",
      "Class Weights: tensor([1.8914, 0.6797])\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df[\"label\"].value_counts().sort_index()\n",
    "\n",
    "num_normal = class_counts[0]\n",
    "num_pneumonia = class_counts[1]\n",
    "\n",
    "print(\"Normal:\", num_normal)\n",
    "print(\"Pneumonia:\", num_pneumonia)\n",
    "\n",
    "total = num_normal + num_pneumonia\n",
    "\n",
    "weight_normal = total / (2 * num_normal)\n",
    "weight_pneumonia = total / (2 * num_pneumonia)\n",
    "\n",
    "class_weights = torch.tensor(\n",
    "    [weight_normal, weight_pneumonia],\n",
    "    dtype=torch.float\n",
    ").to(device)\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02d706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model, target_layer = get_model(model_name=model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f82ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed757b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = f\"{model_name}_{augmentation}_CW.pt\"\n",
    "metrics_filename = f\"{model_name}_{augmentation}_CW.npz\"\n",
    "\n",
    "model_save_path = os.path.join(models_dir, model_filename)\n",
    "metrics_save_path = os.path.join(metrics_dir, metrics_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d2a5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Treino]:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 0.1510\n",
      "Val Loss:   0.0981\n",
      "Val AUC:    0.9977\n",
      "Val F1:     0.9742\n",
      "Val Recall: 0.9530\n",
      "Val Prec.:  0.9964\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0801\n",
      "Val Loss:   0.1152\n",
      "Val AUC:    0.9980\n",
      "Val F1:     0.9706\n",
      "Val Recall: 0.9450\n",
      "Val Prec.:  0.9976\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0632\n",
      "Val Loss:   0.1584\n",
      "Val AUC:    0.9979\n",
      "Val F1:     0.9662\n",
      "Val Recall: 0.9346\n",
      "Val Prec.:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0574\n",
      "Val Loss:   0.0433\n",
      "Val AUC:    0.9985\n",
      "Val F1:     0.9891\n",
      "Val Recall: 0.9874\n",
      "Val Prec.:  0.9908\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0370\n",
      "Val Loss:   0.0491\n",
      "Val AUC:    0.9990\n",
      "Val F1:     0.9879\n",
      "Val Recall: 0.9805\n",
      "Val Prec.:  0.9953\n",
      "→ Novo melhor modelo salvo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0396\n",
      "Val Loss:   0.0399\n",
      "Val AUC:    0.9985\n",
      "Val F1:     0.9908\n",
      "Val Recall: 0.9931\n",
      "Val Prec.:  0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0381\n",
      "Val Loss:   0.2093\n",
      "Val AUC:    0.9983\n",
      "Val F1:     0.9576\n",
      "Val Recall: 0.9186\n",
      "Val Prec.:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0285\n",
      "Val Loss:   0.0669\n",
      "Val AUC:    0.9982\n",
      "Val F1:     0.9855\n",
      "Val Recall: 0.9759\n",
      "Val Prec.:  0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0263\n",
      "Val Loss:   0.0797\n",
      "Val AUC:    0.9983\n",
      "Val F1:     0.9831\n",
      "Val Recall: 0.9690\n",
      "Val Prec.:  0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0136\n",
      "Val Loss:   0.0438\n",
      "Val AUC:    0.9987\n",
      "Val F1:     0.9897\n",
      "Val Recall: 0.9920\n",
      "Val Prec.:  0.9874\n",
      "\n",
      "Melhor AUC obtida: 0.999003539154039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "history, best_auc = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs,\n",
    "    model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e952dfbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m metrics_dict \u001b[38;5;241m=\u001b[39m history\n\u001b[0;32m      2\u001b[0m metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m best_auc\n\u001b[1;32m----> 4\u001b[0m \u001b[43msave_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo salvo em:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_save_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMétricas salvas em:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics_save_path)\n",
      "File \u001b[1;32mc:\\projects\\xray-project\\src\\utils.py:43\u001b[0m, in \u001b[0;36msave_metrics\u001b[1;34m(metrics_dict, save_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_metrics\u001b[39m(metrics_dict, save_path):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Salva métricas em formato .npz para análise posterior.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(save_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetrics_dict)\n",
      "File \u001b[1;32mc:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:683\u001b[0m, in \u001b[0;36msavez\u001b[1;34m(file, allow_pickle, *args, **kwds)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_dispatcher)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msavez\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \n\u001b[0;32m    594\u001b[0m \u001b[38;5;124;03m    Provide arrays as keyword arguments to store them under the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    681\u001b[0m \n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\honor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:793\u001b[0m, in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    792\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 793\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;66;03m# always force zip64, gh-10776\u001b[39;00m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipf\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "metrics_dict = history\n",
    "metrics_dict[\"best_auc\"] = best_auc\n",
    "\n",
    "save_metrics(metrics_dict, metrics_save_path)\n",
    "\n",
    "print(\"Modelo salvo em:\", model_save_path)\n",
    "print(\"Métricas salvas em:\", metrics_save_path)\n",
    "print(\"Melhor AUC:\", best_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
